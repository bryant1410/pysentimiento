{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset lince (/home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ed95c9302e45f6bbc7c47eada13e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-f8462a766744bd0d.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-b2415cc41a42ddca.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-302bcedfefea246f.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-986aab105c31f86f.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-c56998e93fa6679b.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/pos_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-3b2bc24f000dff30.arrow\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import DatasetDict\n",
    "from pysentimiento.lince.pos import load_datasets, id2label\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(\"es\")\n",
    "\n",
    "lince_pos = DatasetDict(\n",
    "    train=train_dataset,\n",
    "    validation=dev_dataset,\n",
    "    test=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VERB',\n",
       " 'PUNCT',\n",
       " 'PRON',\n",
       " 'NOUN',\n",
       " 'DET',\n",
       " 'ADV',\n",
       " 'ADP',\n",
       " 'INTJ',\n",
       " 'CONJ',\n",
       " 'ADJ',\n",
       " 'AUX',\n",
       " 'SCONJ',\n",
       " 'PART',\n",
       " 'PROPN',\n",
       " 'NUM',\n",
       " 'UNK',\n",
       " 'X']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in lince_pos[\"train\"]:\n",
    "    assert all(x is not None for x in ex[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puede pasar que haya etiquetas que no estén en dev o test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags = set(tag for ex in lince_pos[\"train\"] for tag in ex[\"pos\"])\n",
    "dev_tags = set(tag for ex in lince_pos[\"validation\"] for tag in ex[\"pos\"])\n",
    "\n",
    "train_tags == dev_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'words', 'lid', 'pos', 'labels'],\n",
       "        num_rows: 27893\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'words', 'lid', 'pos', 'labels'],\n",
       "        num_rows: 4298\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'words', 'lid', 'pos', 'labels'],\n",
       "        num_rows: 10720\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lince_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pysentimiento/robertuito-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c7fede3043435f997127a3419c5918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1564c8466b4930830db51379799069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3a4ecc2ff44fedb1583fb3578548c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pysentimiento.training import load_model\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from pysentimiento.lince.pos import label2id, id2label, tokenize_and_align_labels\n",
    "\n",
    "base_model = \"pysentimiento/robertuito-base-uncased\"\n",
    "\n",
    "max_length = 128\n",
    "model, tokenizer = load_model(\n",
    "    base_model, label2id=label2id, id2label=id2label,\n",
    "    max_length=max_length,\n",
    "    auto_class=AutoModelForTokenClassification\n",
    ")\n",
    "\n",
    "tokenized_datasets = lince_pos.map(\n",
    "    lambda x: tokenize_and_align_labels(x, tokenizer),\n",
    "    batched=True,\n",
    "    #remove_columns=lince_ner[\"train\"].column_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcf73353dfa4755b85246d447461d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223c5f3f985f43a9922bbac2e0713acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620d184c09745288f4c97016ec7eafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 problematic examples\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "problematic = []\n",
    "\n",
    "for split in tokenized_datasets:\n",
    "    for idx, ex in tqdm(enumerate(tokenized_datasets[split]), total=len(tokenized_datasets[split])):\n",
    "        if not (len(ex[\"words\"]) == (ex[\"word_ids\"][-2] + 1)):\n",
    "            problematic.append((split, idx))\n",
    "\n",
    "print(f\"{len(problematic)} problematic examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lince_pos[\"train\"][10310][\"words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, es un problema del largo del tweet (qué ganas de romper las bolas que tienen, 138 palabras!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.config.num_labels == len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running training *****\n",
      "  Num examples = 27893\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4360' max='4360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4360/4360 10:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Art F1</th>\n",
       "      <th>Art Precision</th>\n",
       "      <th>Art Recall</th>\n",
       "      <th>Conj F1</th>\n",
       "      <th>Conj Precision</th>\n",
       "      <th>Conj Recall</th>\n",
       "      <th>Dj F1</th>\n",
       "      <th>Dj Precision</th>\n",
       "      <th>Dj Recall</th>\n",
       "      <th>Dp F1</th>\n",
       "      <th>Dp Precision</th>\n",
       "      <th>Dp Recall</th>\n",
       "      <th>Dv F1</th>\n",
       "      <th>Dv Precision</th>\n",
       "      <th>Dv Recall</th>\n",
       "      <th>Erb F1</th>\n",
       "      <th>Erb Precision</th>\n",
       "      <th>Erb Recall</th>\n",
       "      <th>Et F1</th>\n",
       "      <th>Et Precision</th>\n",
       "      <th>Et Recall</th>\n",
       "      <th>Nk F1</th>\n",
       "      <th>Nk Precision</th>\n",
       "      <th>Nk Recall</th>\n",
       "      <th>Ntj F1</th>\n",
       "      <th>Ntj Precision</th>\n",
       "      <th>Ntj Recall</th>\n",
       "      <th>Onj F1</th>\n",
       "      <th>Onj Precision</th>\n",
       "      <th>Onj Recall</th>\n",
       "      <th>Oun F1</th>\n",
       "      <th>Oun Precision</th>\n",
       "      <th>Oun Recall</th>\n",
       "      <th>Ron F1</th>\n",
       "      <th>Ron Precision</th>\n",
       "      <th>Ron Recall</th>\n",
       "      <th>Ropn F1</th>\n",
       "      <th>Ropn Precision</th>\n",
       "      <th>Ropn Recall</th>\n",
       "      <th>Um F1</th>\n",
       "      <th>Um Precision</th>\n",
       "      <th>Um Recall</th>\n",
       "      <th>Unct F1</th>\n",
       "      <th>Unct Precision</th>\n",
       "      <th>Unct Recall</th>\n",
       "      <th>Ux F1</th>\n",
       "      <th>Ux Precision</th>\n",
       "      <th>Ux Recall</th>\n",
       "      <th>  F1</th>\n",
       "      <th>  Precision</th>\n",
       "      <th>  Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.107150</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>0.960593</td>\n",
       "      <td>0.892303</td>\n",
       "      <td>0.959195</td>\n",
       "      <td>0.965482</td>\n",
       "      <td>0.975912</td>\n",
       "      <td>0.972565</td>\n",
       "      <td>0.979282</td>\n",
       "      <td>0.905767</td>\n",
       "      <td>0.882998</td>\n",
       "      <td>0.929740</td>\n",
       "      <td>0.870998</td>\n",
       "      <td>0.862873</td>\n",
       "      <td>0.879278</td>\n",
       "      <td>0.959092</td>\n",
       "      <td>0.973219</td>\n",
       "      <td>0.945369</td>\n",
       "      <td>0.904090</td>\n",
       "      <td>0.889794</td>\n",
       "      <td>0.918852</td>\n",
       "      <td>0.965609</td>\n",
       "      <td>0.966622</td>\n",
       "      <td>0.964598</td>\n",
       "      <td>0.968785</td>\n",
       "      <td>0.961758</td>\n",
       "      <td>0.975914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939919</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.994845</td>\n",
       "      <td>0.995701</td>\n",
       "      <td>0.993991</td>\n",
       "      <td>0.943732</td>\n",
       "      <td>0.931459</td>\n",
       "      <td>0.956333</td>\n",
       "      <td>0.974858</td>\n",
       "      <td>0.975969</td>\n",
       "      <td>0.973749</td>\n",
       "      <td>0.865221</td>\n",
       "      <td>0.923541</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931870</td>\n",
       "      <td>0.909010</td>\n",
       "      <td>0.955910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.096968</td>\n",
       "      <td>0.962434</td>\n",
       "      <td>0.963851</td>\n",
       "      <td>0.897846</td>\n",
       "      <td>0.963142</td>\n",
       "      <td>0.968931</td>\n",
       "      <td>0.986264</td>\n",
       "      <td>0.980874</td>\n",
       "      <td>0.991713</td>\n",
       "      <td>0.906768</td>\n",
       "      <td>0.891993</td>\n",
       "      <td>0.922040</td>\n",
       "      <td>0.879100</td>\n",
       "      <td>0.866913</td>\n",
       "      <td>0.891635</td>\n",
       "      <td>0.963253</td>\n",
       "      <td>0.965013</td>\n",
       "      <td>0.961498</td>\n",
       "      <td>0.906375</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.900544</td>\n",
       "      <td>0.970083</td>\n",
       "      <td>0.968152</td>\n",
       "      <td>0.972021</td>\n",
       "      <td>0.971569</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942238</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.938849</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.998276</td>\n",
       "      <td>0.993991</td>\n",
       "      <td>0.951246</td>\n",
       "      <td>0.951934</td>\n",
       "      <td>0.950559</td>\n",
       "      <td>0.977479</td>\n",
       "      <td>0.977076</td>\n",
       "      <td>0.977883</td>\n",
       "      <td>0.895871</td>\n",
       "      <td>0.907273</td>\n",
       "      <td>0.884752</td>\n",
       "      <td>0.978056</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938945</td>\n",
       "      <td>0.926095</td>\n",
       "      <td>0.952158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.096270</td>\n",
       "      <td>0.962650</td>\n",
       "      <td>0.964822</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.963735</td>\n",
       "      <td>0.969741</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.974290</td>\n",
       "      <td>0.994475</td>\n",
       "      <td>0.907795</td>\n",
       "      <td>0.896714</td>\n",
       "      <td>0.919153</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.884030</td>\n",
       "      <td>0.966075</td>\n",
       "      <td>0.969110</td>\n",
       "      <td>0.963059</td>\n",
       "      <td>0.910253</td>\n",
       "      <td>0.904692</td>\n",
       "      <td>0.915883</td>\n",
       "      <td>0.970585</td>\n",
       "      <td>0.970863</td>\n",
       "      <td>0.970308</td>\n",
       "      <td>0.971606</td>\n",
       "      <td>0.966461</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941997</td>\n",
       "      <td>0.961769</td>\n",
       "      <td>0.923022</td>\n",
       "      <td>0.995273</td>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.993991</td>\n",
       "      <td>0.952878</td>\n",
       "      <td>0.949803</td>\n",
       "      <td>0.955973</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>0.973608</td>\n",
       "      <td>0.976023</td>\n",
       "      <td>0.896116</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.978056</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939297</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.965291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.104851</td>\n",
       "      <td>0.963247</td>\n",
       "      <td>0.964665</td>\n",
       "      <td>0.898674</td>\n",
       "      <td>0.963955</td>\n",
       "      <td>0.969981</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.979424</td>\n",
       "      <td>0.986188</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.914505</td>\n",
       "      <td>0.916266</td>\n",
       "      <td>0.883430</td>\n",
       "      <td>0.895508</td>\n",
       "      <td>0.871673</td>\n",
       "      <td>0.965104</td>\n",
       "      <td>0.966111</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.909674</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.911925</td>\n",
       "      <td>0.969518</td>\n",
       "      <td>0.970442</td>\n",
       "      <td>0.968595</td>\n",
       "      <td>0.971466</td>\n",
       "      <td>0.963581</td>\n",
       "      <td>0.979483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>0.960972</td>\n",
       "      <td>0.938849</td>\n",
       "      <td>0.995701</td>\n",
       "      <td>0.997416</td>\n",
       "      <td>0.993991</td>\n",
       "      <td>0.953442</td>\n",
       "      <td>0.949857</td>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.975952</td>\n",
       "      <td>0.974644</td>\n",
       "      <td>0.977263</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.923507</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.965300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936847</td>\n",
       "      <td>0.908370</td>\n",
       "      <td>0.967167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.108149</td>\n",
       "      <td>0.964319</td>\n",
       "      <td>0.965981</td>\n",
       "      <td>0.900564</td>\n",
       "      <td>0.965149</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.986924</td>\n",
       "      <td>0.983539</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.918001</td>\n",
       "      <td>0.925636</td>\n",
       "      <td>0.910491</td>\n",
       "      <td>0.885823</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.884981</td>\n",
       "      <td>0.964406</td>\n",
       "      <td>0.963155</td>\n",
       "      <td>0.965661</td>\n",
       "      <td>0.909631</td>\n",
       "      <td>0.910307</td>\n",
       "      <td>0.908956</td>\n",
       "      <td>0.970406</td>\n",
       "      <td>0.970314</td>\n",
       "      <td>0.970499</td>\n",
       "      <td>0.971896</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.979483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947406</td>\n",
       "      <td>0.948773</td>\n",
       "      <td>0.946043</td>\n",
       "      <td>0.995701</td>\n",
       "      <td>0.997416</td>\n",
       "      <td>0.993991</td>\n",
       "      <td>0.956867</td>\n",
       "      <td>0.957040</td>\n",
       "      <td>0.956694</td>\n",
       "      <td>0.977897</td>\n",
       "      <td>0.977291</td>\n",
       "      <td>0.978504</td>\n",
       "      <td>0.905830</td>\n",
       "      <td>0.916515</td>\n",
       "      <td>0.895390</td>\n",
       "      <td>0.978056</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940744</td>\n",
       "      <td>0.921692</td>\n",
       "      <td>0.960600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4298\n",
      "  Batch size = 32\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /tmp/pysentimiento-prueba/checkpoint-872\n",
      "Configuration saved in /tmp/pysentimiento-prueba/checkpoint-872/config.json\n",
      "Model weights saved in /tmp/pysentimiento-prueba/checkpoint-872/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/pysentimiento-prueba/checkpoint-872/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/pysentimiento-prueba/checkpoint-872/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4298\n",
      "  Batch size = 32\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /tmp/pysentimiento-prueba/checkpoint-1744\n",
      "Configuration saved in /tmp/pysentimiento-prueba/checkpoint-1744/config.json\n",
      "Model weights saved in /tmp/pysentimiento-prueba/checkpoint-1744/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/pysentimiento-prueba/checkpoint-1744/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/pysentimiento-prueba/checkpoint-1744/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4298\n",
      "  Batch size = 32\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /tmp/pysentimiento-prueba/checkpoint-2616\n",
      "Configuration saved in /tmp/pysentimiento-prueba/checkpoint-2616/config.json\n",
      "Model weights saved in /tmp/pysentimiento-prueba/checkpoint-2616/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/pysentimiento-prueba/checkpoint-2616/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/pysentimiento-prueba/checkpoint-2616/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4298\n",
      "  Batch size = 32\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /tmp/pysentimiento-prueba/checkpoint-3488\n",
      "Configuration saved in /tmp/pysentimiento-prueba/checkpoint-3488/config.json\n",
      "Model weights saved in /tmp/pysentimiento-prueba/checkpoint-3488/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/pysentimiento-prueba/checkpoint-3488/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/pysentimiento-prueba/checkpoint-3488/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: word_ids, pos, words, lid, idx.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4298\n",
      "  Batch size = 32\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/jmperez/.cache/pypoetry/virtualenvs/pysentimiento-bwlKzHxB-py3.7/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /tmp/pysentimiento-prueba/checkpoint-4360\n",
      "Configuration saved in /tmp/pysentimiento-prueba/checkpoint-4360/config.json\n",
      "Model weights saved in /tmp/pysentimiento-prueba/checkpoint-4360/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/pysentimiento-prueba/checkpoint-4360/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/pysentimiento-prueba/checkpoint-4360/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4360, training_loss=0.1496922724837557, metrics={'train_runtime': 613.114, 'train_samples_per_second': 227.47, 'train_steps_per_second': 7.111, 'total_flos': 2300710943790330.0, 'train_loss': 0.1496922724837557, 'epoch': 5.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from pysentimiento.lince.pos import compute_metrics\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/pysentimiento-prueba\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_ratio=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer_args = {\n",
    "    \"model\": model,\n",
    "    \"args\": training_args,\n",
    "    \"compute_metrics\": compute_metrics,\n",
    "    \"train_dataset\": tokenized_datasets[\"train\"],\n",
    "    \"eval_dataset\": tokenized_datasets[\"validation\"],\n",
    "    \"data_collator\": data_collator,\n",
    "    \"tokenizer\": tokenizer,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**trainer_args)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
