{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "In this notebook we show the results of our experiments for both tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertin.json\t   birnn_twitter.json  mbert_uncased.json  robertuito.json\n",
      "beto_cased.json    electricidad.json   rnn_cc.json\n",
      "beto_uncased.json  ffn_cc.json\t       rnn_twitter.json\n",
      "birnn_cc.json\t   ffn_twitter.json    roberta.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "base_path = \"../evaluations/es\"\n",
    "!ls $base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../evaluations/es/roberta.json\n",
      "../evaluations/es/birnn_twitter.json\n",
      "../evaluations/es/mbert_uncased.json\n",
      "../evaluations/es/rnn_twitter.json\n",
      "../evaluations/es/rnn_cc.json\n",
      "../evaluations/es/beto_cased.json\n",
      "../evaluations/es/robertuito.json\n",
      "../evaluations/es/ffn_cc.json\n",
      "../evaluations/es/bertin.json\n",
      "../evaluations/es/ffn_twitter.json\n",
      "../evaluations/es/birnn_cc.json\n",
      "../evaluations/es/electricidad.json\n",
      "../evaluations/es/beto_uncased.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta', 'birnn_twitter', 'mbert_uncased', 'rnn_twitter', 'rnn_cc', 'beto_cased', 'robertuito', 'ffn_cc', 'bertin', 'ffn_twitter', 'birnn_cc', 'electricidad', 'beto_uncased'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "def clean_key(k):\n",
    "    return k.split(\"_\", 1)[1]\n",
    "\n",
    "\n",
    "evaluation_paths = glob.glob(f\"{base_path}/*.json\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "for path in evaluation_paths:\n",
    "    print(path)\n",
    "    name = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path) as f:\n",
    "        model_evaluation = json.load(f)\n",
    "        clean_evaluations = []\n",
    "        for task in model_evaluation[\"evaluations\"].keys():\n",
    "            task_evaluations = model_evaluation[\"evaluations\"][task]\n",
    "            clean_evaluations = [\n",
    "                {clean_key(k): v for k, v in ev.items()} \n",
    "                for ev in task_evaluations\n",
    "            ]\n",
    "\n",
    "            model_evaluation[\"evaluations\"][task] = clean_evaluations\n",
    "        models[name] = model_evaluation\n",
    "        \n",
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "roberta\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "birnn_twitter\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "mbert_uncased\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "rnn_twitter\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "rnn_cc\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "beto_cased\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "robertuito\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "ffn_cc\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "bertin\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "9\n",
      "==================================================\n",
      "ffn_twitter\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "birnn_cc\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "==================================================\n",
      "electricidad\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n",
      "ner\n",
      "10\n",
      "pos\n",
      "10\n",
      "lince_sentiment\n",
      "10\n",
      "==================================================\n",
      "beto_uncased\n",
      "hate_speech\n",
      "10\n",
      "sentiment\n",
      "10\n",
      "emotion\n",
      "10\n",
      "irony\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"hate_speech\": \"macro_f1\",\n",
    "    \"sentiment\": \"macro_f1\",\n",
    "    \"emotion\": \"macro_f1\",\n",
    "    \"irony\": \"macro_f1\",\n",
    "    \"ner\": \"micro_f1\",\n",
    "    \"pos\": \"accuracy\",\n",
    "    \"lince_sentiment\": \"macro_f1\"\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model, model_evaluation in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(model)\n",
    "    for task, task_evaluations in model_evaluation[\"evaluations\"].items():\n",
    "        print(task)\n",
    "        print(len(task_evaluations))\n",
    "        for evaluation in task_evaluations:\n",
    "            metric = metrics[task]\n",
    "\n",
    "            ## TODO\n",
    "            if metric not in evaluation:\n",
    "                metric = \"hateful_f1\"\n",
    "            results.append({\n",
    "                \"model\": model,\n",
    "                \"task\": task,\n",
    "                \"metric\": evaluation[metric],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task</th>\n",
       "      <th>emotion</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>irony</th>\n",
       "      <th>lince_sentiment</th>\n",
       "      <th>ner</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>robertuito</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.739</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.721</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_uncased</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.701</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_cased</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.705</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricidad</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_uncased</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.681</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birnn_twitter</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.631</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_twitter</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.628</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birnn_cc</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.625</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_cc</th>\n",
       "      <td>0.237</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.581</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffn_twitter</th>\n",
       "      <td>0.202</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.579</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffn_cc</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.511</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task           emotion  hate_speech  irony  lince_sentiment   ner   pos  \\\n",
       "model                                                                     \n",
       "robertuito       0.560        0.759  0.739              nan   nan   nan   \n",
       "roberta          0.527        0.741  0.721              nan   nan   nan   \n",
       "bertin           0.524        0.738  0.713              nan   nan   nan   \n",
       "beto_uncased     0.532        0.727  0.701              nan   nan   nan   \n",
       "beto_cased       0.516        0.724  0.705              nan   nan   nan   \n",
       "electricidad     0.455        0.722  0.680            0.508 0.569 0.965   \n",
       "mbert_uncased    0.493        0.718  0.681              nan   nan   nan   \n",
       "birnn_twitter    0.264        0.592  0.631              nan   nan   nan   \n",
       "rnn_twitter      0.269        0.538  0.628              nan   nan   nan   \n",
       "birnn_cc         0.231        0.534  0.625              nan   nan   nan   \n",
       "rnn_cc           0.237        0.516  0.581              nan   nan   nan   \n",
       "ffn_twitter      0.202        0.444  0.579              nan   nan   nan   \n",
       "ffn_cc           0.173        0.392  0.511              nan   nan   nan   \n",
       "\n",
       "task           sentiment  score  \n",
       "model                            \n",
       "robertuito         0.705  0.691  \n",
       "roberta            0.670  0.665  \n",
       "bertin             0.666  0.660  \n",
       "beto_uncased       0.651  0.653  \n",
       "beto_cased         0.662  0.652  \n",
       "electricidad       0.655  0.651  \n",
       "mbert_uncased      0.617  0.627  \n",
       "birnn_twitter      0.585  0.518  \n",
       "rnn_twitter        0.602  0.509  \n",
       "birnn_cc           0.553  0.486  \n",
       "rnn_cc             0.564  0.474  \n",
       "ffn_twitter        0.538  0.441  \n",
       "ffn_cc             0.511  0.397  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "mean_df = pd.DataFrame(results).groupby([\"model\", \"task\"]).mean().stack()\n",
    "std_df = pd.DataFrame(results).groupby([\"model\", \"task\"]).std().stack()\n",
    "# Magia negra\n",
    "mean_df.index = mean_df.index.droplevel(-1)\n",
    "std_df.index = std_df.index.droplevel(-1)\n",
    "\n",
    "mean_df = mean_df.unstack(1)\n",
    "std_df = std_df.unstack(1)\n",
    "\n",
    "mean_df[\"score\"] = mean_df.mean(1)\n",
    "\n",
    "mean_df.sort_values(\"score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>irony</th>\n",
       "      <th>lince_sentiment</th>\n",
       "      <th>ner</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>robertuito</th>\n",
       "      <td>0.560 ± 0.010</td>\n",
       "      <td>0.759 ± 0.007</td>\n",
       "      <td>0.739 ± 0.005</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.705 ± 0.003</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta</th>\n",
       "      <td>0.527 ± 0.015</td>\n",
       "      <td>0.741 ± 0.012</td>\n",
       "      <td>0.721 ± 0.008</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.670 ± 0.006</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.524 ± 0.007</td>\n",
       "      <td>0.738 ± 0.007</td>\n",
       "      <td>0.713 ± 0.012</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.666 ± 0.005</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_uncased</th>\n",
       "      <td>0.532 ± 0.012</td>\n",
       "      <td>0.727 ± 0.016</td>\n",
       "      <td>0.701 ± 0.007</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.651 ± 0.006</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_cased</th>\n",
       "      <td>0.516 ± 0.012</td>\n",
       "      <td>0.724 ± 0.012</td>\n",
       "      <td>0.705 ± 0.009</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.662 ± 0.005</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricidad</th>\n",
       "      <td>0.455 ± 0.030</td>\n",
       "      <td>0.722 ± 0.009</td>\n",
       "      <td>0.680 ± 0.014</td>\n",
       "      <td>0.508 ± 0.009</td>\n",
       "      <td>0.569 ± 0.006</td>\n",
       "      <td>0.965 ± 0.000</td>\n",
       "      <td>0.655 ± 0.004</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_uncased</th>\n",
       "      <td>0.493 ± 0.010</td>\n",
       "      <td>0.718 ± 0.011</td>\n",
       "      <td>0.681 ± 0.010</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.617 ± 0.003</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birnn_twitter</th>\n",
       "      <td>0.264 ± 0.007</td>\n",
       "      <td>0.592 ± 0.018</td>\n",
       "      <td>0.631 ± 0.011</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.585 ± 0.011</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_twitter</th>\n",
       "      <td>0.269 ± 0.003</td>\n",
       "      <td>0.538 ± 0.014</td>\n",
       "      <td>0.628 ± 0.014</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.602 ± 0.004</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birnn_cc</th>\n",
       "      <td>0.231 ± 0.006</td>\n",
       "      <td>0.534 ± 0.022</td>\n",
       "      <td>0.625 ± 0.009</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.553 ± 0.008</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_cc</th>\n",
       "      <td>0.237 ± 0.005</td>\n",
       "      <td>0.516 ± 0.006</td>\n",
       "      <td>0.581 ± 0.016</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.564 ± 0.004</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffn_twitter</th>\n",
       "      <td>0.202 ± 0.002</td>\n",
       "      <td>0.444 ± 0.005</td>\n",
       "      <td>0.579 ± 0.012</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.538 ± 0.005</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffn_cc</th>\n",
       "      <td>0.173 ± 0.002</td>\n",
       "      <td>0.392 ± 0.001</td>\n",
       "      <td>0.511 ± 0.005</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.511 ± 0.003</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     emotion    hate_speech          irony lince_sentiment  \\\n",
       "model                                                                        \n",
       "robertuito     0.560 ± 0.010  0.759 ± 0.007  0.739 ± 0.005       nan ± nan   \n",
       "roberta        0.527 ± 0.015  0.741 ± 0.012  0.721 ± 0.008       nan ± nan   \n",
       "bertin         0.524 ± 0.007  0.738 ± 0.007  0.713 ± 0.012       nan ± nan   \n",
       "beto_uncased   0.532 ± 0.012  0.727 ± 0.016  0.701 ± 0.007       nan ± nan   \n",
       "beto_cased     0.516 ± 0.012  0.724 ± 0.012  0.705 ± 0.009       nan ± nan   \n",
       "electricidad   0.455 ± 0.030  0.722 ± 0.009  0.680 ± 0.014   0.508 ± 0.009   \n",
       "mbert_uncased  0.493 ± 0.010  0.718 ± 0.011  0.681 ± 0.010       nan ± nan   \n",
       "birnn_twitter  0.264 ± 0.007  0.592 ± 0.018  0.631 ± 0.011       nan ± nan   \n",
       "rnn_twitter    0.269 ± 0.003  0.538 ± 0.014  0.628 ± 0.014       nan ± nan   \n",
       "birnn_cc       0.231 ± 0.006  0.534 ± 0.022  0.625 ± 0.009       nan ± nan   \n",
       "rnn_cc         0.237 ± 0.005  0.516 ± 0.006  0.581 ± 0.016       nan ± nan   \n",
       "ffn_twitter    0.202 ± 0.002  0.444 ± 0.005  0.579 ± 0.012       nan ± nan   \n",
       "ffn_cc         0.173 ± 0.002  0.392 ± 0.001  0.511 ± 0.005       nan ± nan   \n",
       "\n",
       "                         ner            pos      sentiment  score  \n",
       "model                                                              \n",
       "robertuito         nan ± nan      nan ± nan  0.705 ± 0.003  0.691  \n",
       "roberta            nan ± nan      nan ± nan  0.670 ± 0.006  0.665  \n",
       "bertin             nan ± nan      nan ± nan  0.666 ± 0.005  0.660  \n",
       "beto_uncased       nan ± nan      nan ± nan  0.651 ± 0.006  0.653  \n",
       "beto_cased         nan ± nan      nan ± nan  0.662 ± 0.005  0.652  \n",
       "electricidad   0.569 ± 0.006  0.965 ± 0.000  0.655 ± 0.004  0.651  \n",
       "mbert_uncased      nan ± nan      nan ± nan  0.617 ± 0.003  0.627  \n",
       "birnn_twitter      nan ± nan      nan ± nan  0.585 ± 0.011  0.518  \n",
       "rnn_twitter        nan ± nan      nan ± nan  0.602 ± 0.004  0.509  \n",
       "birnn_cc           nan ± nan      nan ± nan  0.553 ± 0.008  0.486  \n",
       "rnn_cc             nan ± nan      nan ± nan  0.564 ± 0.004  0.474  \n",
       "ffn_twitter        nan ± nan      nan ± nan  0.538 ± 0.005  0.441  \n",
       "ffn_cc             nan ± nan      nan ± nan  0.511 ± 0.003  0.397  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for col in mean_df:\n",
    "    if col == \"score\":\n",
    "        continue\n",
    "    result_df[col] = mean_df[col].apply(lambda x: f\"{x:.3f}\") + \" ± \" + std_df[col].apply(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "result_df[\"score\"] = mean_df[\"score\"]\n",
    "\n",
    "result_df = result_df.sort_values(\"score\", ascending=False)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model         | emotion       | hate_speech   | irony         | sentiment     |    score |\n",
      "|:--------------|:--------------|:--------------|:--------------|:--------------|---------:|\n",
      "| robertuito    | 0.560 ± 0.010 | 0.759 ± 0.007 | 0.739 ± 0.005 | 0.705 ± 0.003 | 0.690734 |\n",
      "| roberta       | 0.527 ± 0.015 | 0.741 ± 0.012 | 0.721 ± 0.008 | 0.670 ± 0.006 | 0.664632 |\n",
      "| bertin        | 0.524 ± 0.007 | 0.738 ± 0.007 | 0.713 ± 0.012 | 0.666 ± 0.005 | 0.660141 |\n",
      "| beto_uncased  | 0.532 ± 0.012 | 0.727 ± 0.016 | 0.701 ± 0.007 | 0.651 ± 0.006 | 0.652608 |\n",
      "| beto_cased    | 0.516 ± 0.012 | 0.724 ± 0.012 | 0.705 ± 0.009 | 0.662 ± 0.005 | 0.651739 |\n",
      "| mbert_uncased | 0.493 ± 0.010 | 0.718 ± 0.011 | 0.681 ± 0.010 | 0.617 ± 0.003 | 0.627368 |\n",
      "| birnn_twitter | 0.264 ± 0.007 | 0.592 ± 0.018 | 0.631 ± 0.011 | 0.585 ± 0.011 | 0.518025 |\n",
      "| rnn_twitter   | 0.269 ± 0.003 | 0.538 ± 0.014 | 0.628 ± 0.014 | 0.602 ± 0.004 | 0.509427 |\n",
      "| birnn_cc      | 0.231 ± 0.006 | 0.534 ± 0.022 | 0.625 ± 0.009 | 0.553 ± 0.008 | 0.485782 |\n",
      "| rnn_cc        | 0.237 ± 0.005 | 0.516 ± 0.006 | 0.581 ± 0.016 | 0.564 ± 0.004 | 0.474446 |\n",
      "| ffn_twitter   | 0.202 ± 0.002 | 0.444 ± 0.005 | 0.579 ± 0.012 | 0.538 ± 0.005 | 0.440567 |\n",
      "| ffn_cc        | 0.173 ± 0.002 | 0.392 ± 0.001 | 0.511 ± 0.005 | 0.511 ± 0.003 | 0.396715 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(result_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "pairs = [\n",
    "    ('birnn_twitter', 'birnn_cc'),\n",
    "    ('rnn_twitter', 'rnn_cc'),\n",
    "    ('ffn_twitter', 'ffn_cc'),\n",
    "]\n",
    "\n",
    "tasks = [\"irony\", \"emotion\", \"sentiment\"]\n",
    "\n",
    "pvals = []\n",
    "\n",
    "for twitter_model, cc_model in pairs:\n",
    "    for task in tasks:\n",
    "        tw_scores = df.loc[(df[\"model\"] == twitter_model) & (df[\"task\"] == task), \"metric\"]\n",
    "        cc_scores = df.loc[(df[\"model\"] == cc_model) & (df[\"task\"] == task), \"metric\"]\n",
    "\n",
    "        pvals.append({\n",
    "            \"model\": twitter_model,\n",
    "            \"task\": task,\n",
    "            \"pval\": scipy.stats.mannwhitneyu(tw_scores, cc_scores, alternative=\"greater\").pvalue,\n",
    "        }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birnn_twitter</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birnn_twitter</td>\n",
       "      <td>emotion</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>birnn_twitter</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnn_twitter</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnn_twitter</td>\n",
       "      <td>emotion</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rnn_twitter</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ffn_twitter</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ffn_twitter</td>\n",
       "      <td>emotion</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffn_twitter</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model       task  pval\n",
       "0  birnn_twitter      irony 0.038\n",
       "1  birnn_twitter    emotion 0.000\n",
       "2  birnn_twitter  sentiment 0.000\n",
       "3    rnn_twitter      irony 0.000\n",
       "4    rnn_twitter    emotion 0.000\n",
       "5    rnn_twitter  sentiment 0.000\n",
       "6    ffn_twitter      irony 0.000\n",
       "7    ffn_twitter    emotion 0.000\n",
       "8    ffn_twitter  sentiment 0.001"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df_pvals = pd.DataFrame(pvals)\n",
    "df_pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03783079, 0.00011743, 0.00011743, 0.00011743, 0.00011743,\n",
       "       0.00011743, 0.00011743, 0.00011743, 0.00073966])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multipletests(df_pvals.pval, alpha=0.05, method=\"fdr_bh\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "937b9937b084de7c01ff6f8c8ec75cb4264b181d3731e2c746ab087eed3df4a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
