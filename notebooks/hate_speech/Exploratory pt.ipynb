{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/paulafortuna/Portuguese-Hate-Speech-Dataset/master/2019-05-28_portuguese_hate_speech_hierarchical_classification.csv\"\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'Hate.speech', 'Sexism', 'Body', 'Racism', 'Ideology',\n",
       "       'Homophobia', 'Origin', 'Religion', 'Health', 'OtherLifestyle',\n",
       "       'Aborting.women', 'Agnostic', 'Argentines', 'Asians', 'Autists',\n",
       "       'Black.Women', 'Blond.women', 'Brazilians.women', 'Chinese',\n",
       "       'Criminals', 'Egyptians', 'Fat.people', 'Football.players.women',\n",
       "       'Gamers', 'Homeless', 'Homeless.women', 'Indigenous', 'Iranians',\n",
       "       'Japaneses', 'Jews', 'Jornalists', 'Latins', 'Left.wing.ideology',\n",
       "       'Men.Feminists', 'Mexicans', 'Muslims.women', 'Nordestines',\n",
       "       'Old.people', 'Polyamorous', 'Poor.people', 'Rural.people', 'Russians',\n",
       "       'Sertanejos', 'Street.artist', 'Ucranians', 'Vegetarians',\n",
       "       'White.people', 'Young.people', 'Old.women', 'Ugly.people',\n",
       "       'Venezuelans', 'Angolans', 'Black.people', 'Disabled.people',\n",
       "       'Fat.women', 'Feminists', 'Gays', 'Immigrants', 'Islamists', 'Lesbians',\n",
       "       'Men', 'Muslims', 'Refugees', 'Trans.women', 'Travestis', 'Women',\n",
       "       'Bissexuals', 'Transexuals', 'Ugly.women', 'Thin.women', 'Arabic',\n",
       "       'East.europeans', 'Africans', 'South.Americans', 'Brazilians',\n",
       "       'Migrants', 'Homossexuals', 'Thin.people', 'Ageing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Hate.speech</th>\n",
       "      <th>Sexism</th>\n",
       "      <th>Body</th>\n",
       "      <th>Racism</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Homophobia</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Thin.women</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>East.europeans</th>\n",
       "      <th>Africans</th>\n",
       "      <th>South.Americans</th>\n",
       "      <th>Brazilians</th>\n",
       "      <th>Migrants</th>\n",
       "      <th>Homossexuals</th>\n",
       "      <th>Thin.people</th>\n",
       "      <th>Ageing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>abri a janela tava uma gorda no apartamento da frente olhando pra baixo e chorando, acho que caiu a empadinha dela</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>a mina é tão gorda quem nem a indireta que mandei pra ela serviu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>quando alguém te chamar de gordo não ligue você é maior que tudo isso</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>@JessicaaFranca uma coisa é rir e fazer piada, outra coisa é usar da fé pra manipular a opinião dos fiéis e ganhar $. se toca loira burra</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>hj eu vi uma gorda tirar as havaianas pra pesar na farmácia e entendi o significado da palavra \"esperança\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>Tem mulher que termina o namoro, fica gorda fica feia palida.. tem umas que e diferente, fica gostosaaa, linda, maravilhosa..</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>riquinha feia e gorda —_ Yha ando aqui a rebolar para a vida  https://t.co/VFxQ9xq4JK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>@g1 só gorda feia cabeluda fedida. Horror. Mulher que se preza nao tem tempo pra babaquice.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>RT @alerodrigues247: Como ser feminista:\\nSer feia e gorda\\nPagar peitinho em passeata\\nSer peluda\\nOdiar homens\\nE achar q isso fará diferença _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>@gbila19 @satsld \\nQue vc é gorda kkk\\nLuana \\nNão \\nNão\\nA verdadeira bet a feia \\nNão\\n10/10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   text  \\\n",
       "382                                  abri a janela tava uma gorda no apartamento da frente olhando pra baixo e chorando, acho que caiu a empadinha dela   \n",
       "427                                                                                    a mina é tão gorda quem nem a indireta que mandei pra ela serviu   \n",
       "433                                                                               quando alguém te chamar de gordo não ligue você é maior que tudo isso   \n",
       "479           @JessicaaFranca uma coisa é rir e fazer piada, outra coisa é usar da fé pra manipular a opinião dos fiéis e ganhar $. se toca loira burra   \n",
       "495                                          hj eu vi uma gorda tirar as havaianas pra pesar na farmácia e entendi o significado da palavra \"esperança\"   \n",
       "...                                                                                                                                                 ...   \n",
       "5222                     Tem mulher que termina o namoro, fica gorda fica feia palida.. tem umas que e diferente, fica gostosaaa, linda, maravilhosa..    \n",
       "5277                                                              riquinha feia e gorda —_ Yha ando aqui a rebolar para a vida  https://t.co/VFxQ9xq4JK   \n",
       "5288                                                        @g1 só gorda feia cabeluda fedida. Horror. Mulher que se preza nao tem tempo pra babaquice.   \n",
       "5370  RT @alerodrigues247: Como ser feminista:\\nSer feia e gorda\\nPagar peitinho em passeata\\nSer peluda\\nOdiar homens\\nE achar q isso fará diferença _   \n",
       "5455                                                     @gbila19 @satsld \\nQue vc é gorda kkk\\nLuana \\nNão \\nNão\\nA verdadeira bet a feia \\nNão\\n10/10   \n",
       "\n",
       "      Hate.speech  Sexism  Body  Racism  Ideology  Homophobia  Origin  \\\n",
       "382             1       1     1       0         0           0       0   \n",
       "427             1       1     1       0         0           0       0   \n",
       "433             1       0     1       0         0           0       0   \n",
       "479             1       1     1       0         0           0       0   \n",
       "495             1       1     1       0         0           0       0   \n",
       "...           ...     ...   ...     ...       ...         ...     ...   \n",
       "5222            1       1     1       0         0           0       0   \n",
       "5277            1       1     1       0         0           0       0   \n",
       "5288            1       1     1       0         0           0       0   \n",
       "5370            1       1     1       0         1           0       0   \n",
       "5455            1       1     1       0         0           0       0   \n",
       "\n",
       "      Religion  Health  ...  Thin.women  Arabic  East.europeans  Africans  \\\n",
       "382          0       0  ...           0       0               0         0   \n",
       "427          0       0  ...           0       0               0         0   \n",
       "433          0       0  ...           0       0               0         0   \n",
       "479          0       0  ...           0       0               0         0   \n",
       "495          0       0  ...           0       0               0         0   \n",
       "...        ...     ...  ...         ...     ...             ...       ...   \n",
       "5222         0       0  ...           0       0               0         0   \n",
       "5277         0       0  ...           0       0               0         0   \n",
       "5288         0       0  ...           0       0               0         0   \n",
       "5370         0       0  ...           0       0               0         0   \n",
       "5455         0       0  ...           0       0               0         0   \n",
       "\n",
       "      South.Americans  Brazilians  Migrants  Homossexuals  Thin.people  Ageing  \n",
       "382                 0           0         0             0            0       0  \n",
       "427                 0           0         0             0            0       0  \n",
       "433                 0           0         0             0            0       0  \n",
       "479                 0           0         0             0            0       0  \n",
       "495                 0           0         0             0            0       0  \n",
       "...               ...         ...       ...           ...          ...     ...  \n",
       "5222                0           0         0             0            0       0  \n",
       "5277                0           0         0             0            0       0  \n",
       "5288                0           0         0             0            0       0  \n",
       "5370                0           0         0             0            0       0  \n",
       "5455                0           0         0             0            0       0  \n",
       "\n",
       "[164 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Racist tweets\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "racist = df[df[\"Body\"] == 1]\n",
    "\n",
    "racist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset hate_speech_portuguese (/users/jmperez/.cache/huggingface/datasets/hate_speech_portuguese/default/1.0.0/20ad7529b5939c566862ef7d6753aa52f92c45aed182decf84abec62c7894062)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7399a100e6de4ae3af65d79572aad455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"hate_speech_portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5668, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3627, 80), (907, 80), (1134, 80))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split df into train, dev, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = ['Hate.speech', 'Sexism', 'Body', 'Racism', 'Ideology',\n",
    "       'Homophobia']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hate.speech    1228\n",
       "Sexism          672\n",
       "Body            164\n",
       "Racism           94\n",
       "Ideology         92\n",
       "Homophobia      322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'Hate.speech', 'Sexism', 'Body', 'Racism', 'Ideology',\n",
       "       'Homophobia', 'Origin', 'Religion', 'Health', 'OtherLifestyle',\n",
       "       'Aborting.women', 'Agnostic', 'Argentines', 'Asians', 'Autists',\n",
       "       'Black.Women', 'Blond.women', 'Brazilians.women', 'Chinese',\n",
       "       'Criminals', 'Egyptians', 'Fat.people', 'Football.players.women',\n",
       "       'Gamers', 'Homeless', 'Homeless.women', 'Indigenous', 'Iranians',\n",
       "       'Japaneses', 'Jews', 'Jornalists', 'Latins', 'Left.wing.ideology',\n",
       "       'Men.Feminists', 'Mexicans', 'Muslims.women', 'Nordestines',\n",
       "       'Old.people', 'Polyamorous', 'Poor.people', 'Rural.people', 'Russians',\n",
       "       'Sertanejos', 'Street.artist', 'Ucranians', 'Vegetarians',\n",
       "       'White.people', 'Young.people', 'Old.women', 'Ugly.people',\n",
       "       'Venezuelans', 'Angolans', 'Black.people', 'Disabled.people',\n",
       "       'Fat.women', 'Feminists', 'Gays', 'Immigrants', 'Islamists', 'Lesbians',\n",
       "       'Men', 'Muslims', 'Refugees', 'Trans.women', 'Travestis', 'Women',\n",
       "       'Bissexuals', 'Transexuals', 'Ugly.women', 'Thin.women', 'Arabic',\n",
       "       'East.europeans', 'Africans', 'South.Americans', 'Brazilians',\n",
       "       'Migrants', 'Homossexuals', 'Thin.people', 'Ageing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2162214/2237971902.py:12: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  train = Dataset.from_pandas(train_df[features], features=features, preserve_index=False)\n",
      "/tmp/ipykernel_2162214/2237971902.py:13: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  dev = Dataset.from_pandas(dev_df[features], features=features, preserve_index=False)\n",
      "/tmp/ipykernel_2162214/2237971902.py:14: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  test = Dataset.from_pandas(test_df[features], features=features, preserve_index=False)\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset, Value, Features, ClassLabel\n",
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "    'Sexism': ClassLabel(num_classes=2, names=[\"non sexist\", \"sexist\"]),\n",
    "    'Body': ClassLabel(num_classes=2, names=[\"non body\", \"body\"]),\n",
    "    'Racism': ClassLabel(num_classes=2, names=[\"non racist\", \"racist\"]),\n",
    "    'Ideology': ClassLabel(num_classes=2, names=[\"non ideological\", \"ideological\"]),\n",
    "    'Homophobia': ClassLabel(num_classes=2, names=[\"non homophobic\", \"homophobic\"]),\n",
    "})\n",
    "\n",
    "\n",
    "train = Dataset.from_pandas(train_df[features], features=features, preserve_index=False)\n",
    "dev = Dataset.from_pandas(dev_df[features], features=features, preserve_index=False)\n",
    "test = Dataset.from_pandas(test_df[features], features=features, preserve_index=False)\n",
    "\n",
    "ds = DatasetDict(\n",
    "    train=train,\n",
    "    dev=dev,\n",
    "    test=test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29274cc823674a44b4a056ed333f4e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d421fe2d574bda9066b9736f920b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23de6cf22864f0e87c7158457462916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020a25f158db4928acf5e68772ff02fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split dev to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98b2bba2cf6499094489be2b7a90669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4a326368d3481dabbd1b457b353542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3605f89930bd4e588cb26cfc18ac64f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09b1f33f0914576ae0e9e20ffecc43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf399bb8aac4365ba7f3bccd029f02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b00276cab742a4b3d731fbbccf6a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e88f52a85bd445891a7b029b7b636b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bdd4b916f6488a921e3a34c8608ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(\"pysentimiento/pt_hate_speech\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration pysentimiento--pt_hate_speech-0a3eb54f07f627a1\n",
      "Found cached dataset parquet (/users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--pt_hate_speech-0a3eb54f07f627a1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054dba7aed4d4b2c95e9fc6fc8e79f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'Sexism', 'Body', 'Racism', 'Ideology', 'Homophobia'],\n",
       "        num_rows: 907\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Sexism', 'Body', 'Racism', 'Ideology', 'Homophobia'],\n",
       "        num_rows: 1134\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'Sexism', 'Body', 'Racism', 'Ideology', 'Homophobia'],\n",
       "        num_rows: 3627\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"pysentimiento/pt_hate_speech\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc79ed69e4c2b5a1db8fa17ebb1e82d66421519e5b018d314116a7b4cda9238"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
