{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"../../data/sentiment/training_set_sentipolc16.csv\"\n",
    "test_path = \"../../data/sentiment/test_set_sentipolc16_gold2000.csv\"\n",
    "\n",
    "# Read SENTIPOLC16 data\n",
    "# Take care that data is separated by commas and double quotes\n",
    "train_df = pd.read_csv(train_path, sep=\",\", quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with csv reader\n",
    "import csv\n",
    "\n",
    "\n",
    "lines = list(open(test_path, \"r\"))\n",
    "\n",
    "reader = csv.reader(lines, quotechar='\"', delimiter=',',\n",
    "                     quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for row in reader:\n",
    "    while len(row) != 9:\n",
    "        # Join last one with commas\n",
    "        last = row.pop()\n",
    "        before_last = row.pop()\n",
    "\n",
    "        row.append(before_last + \",\" + last)\n",
    "    test_data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9: 2000})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(len(t) for t in test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_data, columns=[\"idtwitter\",\"subj\",\"opos\",\"oneg\",\"iro\",\"lpos\",\"lneg\",\"top\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, dev_df = train_test_split(\n",
    "    train_df, test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, Value, Features, ClassLabel\n",
    "\n",
    "features = Features({\n",
    "    'idtwitter': Value('string'),\n",
    "    'text': Value('string'),\n",
    "    'subj': ClassLabel(num_classes=2, names=[\"objective\", \"subjective\"]),\n",
    "    'opos': ClassLabel(num_classes=2, names=[\"obj. non positive\", \"obj,  positive\"]),\n",
    "    \"oneg\": ClassLabel(num_classes=2, names=[\"obj. non negative\", \"obj,  negative\"]),\n",
    "    \"iro\": ClassLabel(num_classes=2, names=[\"non ironic\", \"ironic\"]),\n",
    "    \"lpos\": ClassLabel(num_classes=2, names=[\"lit. non positive\", \"lit. positive\"]),\n",
    "    \"lneg\": ClassLabel(num_classes=2, names=[\"lit. non negative\", \"lit. negative\"]),\n",
    "    \"top\": Value('int64'),\n",
    "})\n",
    "\n",
    "train = Dataset.from_pandas(train_df, features=features, preserve_index=False)\n",
    "dev = Dataset.from_pandas(dev_df, features=features, preserve_index=False)\n",
    "test = Dataset.from_pandas(df_test, features=features, preserve_index=False)\n",
    "\n",
    "ds = DatasetDict(\n",
    "    train=train,\n",
    "    dev=dev,\n",
    "    test=test\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://www.di.unito.it/~tutreeb/sentipolc-evalita16/sentipolc-guidelines2016UPDATED130916.pdf for the guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration pysentimiento--it_sentipolc16-8c8db12a2ed2bd1e\n",
      "WARNING:datasets.builder:Found cached dataset parquet (/users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--it_sentipolc16-8c8db12a2ed2bd1e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d6ac92b5cc4b58b003286cfcb38e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--it_sentipolc16-8c8db12a2ed2bd1e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0a1d8f889d9b04fd.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--it_sentipolc16-8c8db12a2ed2bd1e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-11aa6dec258a6c5d.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--it_sentipolc16-8c8db12a2ed2bd1e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-a2324e4886af8dca.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c558b4fcfb9b4644b3df79ecd1f68308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1482 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92122fe11f02438b91102a2e60350c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5928 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5904f3ec9ea45d5bf37552e58b0129a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['idtwitter', 'text', 'subj', 'opos', 'oneg', 'iro', 'lpos', 'lneg', 'top', 'labels'],\n",
       "        num_rows: 1482\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['idtwitter', 'text', 'subj', 'opos', 'oneg', 'iro', 'lpos', 'lneg', 'top', 'labels'],\n",
       "        num_rows: 5928\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idtwitter', 'text', 'subj', 'opos', 'oneg', 'iro', 'lpos', 'lneg', 'top', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento.sentipolc import load_datasets\n",
    "\n",
    "ds = load_datasets()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pysentimiento.training import train_and_eval\n",
    "from pysentimiento.tuning import get_training_arguments\n",
    "\n",
    "model_name = \"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\"\n",
    "\n",
    "training_args = get_training_arguments(model_name, task_name=\"sentiment\", lang=\"it\", use_defaults_if_not_tuned=True, metric_for_best_model=\"macro_f1\")\n",
    "\n",
    "\n",
    "trainer, test_results = train_and_eval(\n",
    "    model_name, ds, id2label=[\"pos\", \"neg\"], lang=\"it\", training_args=training_args, \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5472076535224915,\n",
       " 'test_pos_f1': 0.5400516795865633,\n",
       " 'test_pos_precision': 0.495260663507109,\n",
       " 'test_pos_recall': 0.59375,\n",
       " 'test_neg_f1': 0.625,\n",
       " 'test_neg_precision': 0.8158995815899581,\n",
       " 'test_neg_recall': 0.5064935064935064,\n",
       " 'test_emr': 0.6425,\n",
       " 'test_macro_f1': 0.5825258493423462,\n",
       " 'test_macro_precision': 0.6555801630020142,\n",
       " 'test_macro_recall': 0.5501217842102051,\n",
       " 'test_runtime': 3.7927,\n",
       " 'test_samples_per_second': 527.325,\n",
       " 'test_steps_per_second': 16.611}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /users/jmperez/.cache/huggingface/hub/models--m-polignano-uniba--bert_uncased_L-12_H-768_A-12_italian_alb3rt0/snapshots/4454cfbc82952da79729e33e81c37a72dc095b4b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /users/jmperez/.cache/huggingface/hub/models--m-polignano-uniba--bert_uncased_L-12_H-768_A-12_italian_alb3rt0/snapshots/4454cfbc82952da79729e33e81c37a72dc095b4b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "3fc79ed69e4c2b5a1db8fa17ebb1e82d66421519e5b018d314116a7b4cda9238"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
