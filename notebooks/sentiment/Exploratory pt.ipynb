{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>865572794016378882</td>\n",
       "      <td>tô passada com esse cara quanta merda pode sai...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865566046320832512</td>\n",
       "      <td>coitada da namorada\\n</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862307799258329089</td>\n",
       "      <td>esse japa não entendi porra nenhuma de orquíde...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864814104745320449</td>\n",
       "      <td>aí vc fica até NUMBER assistindo e acorda cedo...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864665198359183361</td>\n",
       "      <td>imagina que insuportável ter de dar de comer p...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>864097252591194112</td>\n",
       "      <td>lazaro falou bale fitness e ana maria braga es...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>863089429656817665</td>\n",
       "      <td>simpatia na trama das seis ingrid guimarães mo...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>864699532961091584</td>\n",
       "      <td>ocidentais tem mta dificuldade pra aceitar com...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>865628931621232640</td>\n",
       "      <td>USERNAME que horas vc chega em belém / aeropor...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>862456397484740609</td>\n",
       "      <td>não dou conta de cozinhar com apenas minha esp...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0      865572794016378882  tô passada com esse cara quanta merda pode sai...   \n",
       "1      865566046320832512                              coitada da namorada\\n   \n",
       "2      862307799258329089  esse japa não entendi porra nenhuma de orquíde...   \n",
       "3      864814104745320449  aí vc fica até NUMBER assistindo e acorda cedo...   \n",
       "4      864665198359183361  imagina que insuportável ter de dar de comer p...   \n",
       "...                   ...                                                ...   \n",
       "14995  864097252591194112  lazaro falou bale fitness e ana maria braga es...   \n",
       "14996  863089429656817665  simpatia na trama das seis ingrid guimarães mo...   \n",
       "14997  864699532961091584  ocidentais tem mta dificuldade pra aceitar com...   \n",
       "14998  865628931621232640  USERNAME que horas vc chega em belém / aeropor...   \n",
       "14999  862456397484740609  não dou conta de cozinhar com apenas minha esp...   \n",
       "\n",
       "      label  \n",
       "0       NEG  \n",
       "1       NEG  \n",
       "2       NEG  \n",
       "3       NEG  \n",
       "4       NEG  \n",
       "...     ...  \n",
       "14995   NEU  \n",
       "14996   NEU  \n",
       "14997   NEU  \n",
       "14998   NEU  \n",
       "14999   NEU  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "files = [\n",
    "    (\"NEG\", \"../../data/sentiment/ttsbr/tweets.neg\"),\n",
    "    (\"POS\", \"../../data/sentiment/ttsbr/tweets.pos\"),\n",
    "    (\"NEU\", \"../../data/sentiment/ttsbr/tweets.neu\"),\n",
    "]\n",
    "\n",
    "\n",
    "data = []\n",
    "for label, file in files:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            twid, text = line.split(\" \", 1)\n",
    "\n",
    "            data.append({\n",
    "                \"tweet_id\": twid, \n",
    "                \"text\": text,\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS    6648\n",
       "NEG    4426\n",
       "NEU    3926\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 3), (2400, 3), (3000, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "label2id = {\n",
    "    \"NEG\": 0,\n",
    "    \"NEU\": 1,\n",
    "    \"POS\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: label2id[x])\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "train, dev = train_test_split(train, test_size=0.2, random_state=42, stratify=train[\"label\"])\n",
    "\n",
    "train.shape, dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet_id', 'text', 'label'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['tweet_id', 'text', 'label'],\n",
       "        num_rows: 2400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tweet_id', 'text', 'label'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Value, ClassLabel, DatasetDict\n",
    "\n",
    "\n",
    "features = Features({\n",
    "    'tweet_id': Value('string'),\n",
    "    'text': Value('string'),\n",
    "    \"label\": ClassLabel(num_classes=3, names=[\"NEG\", \"NEU\", \"POS\"]),\n",
    "})\n",
    "\n",
    "\n",
    "train = Dataset.from_pandas(train, features=features, preserve_index=False)\n",
    "dev = Dataset.from_pandas(dev, features=features, preserve_index=False)\n",
    "test = Dataset.from_pandas(test, features=features, preserve_index=False)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": train,\n",
    "    \"dev\": dev,\n",
    "    \"test\": test,\n",
    "})\n",
    "\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee608e009ad4f8e9a9b1cfa57b52f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee834295e2b40348a732f24677ab9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54707c2befbf4416a125222c19bab6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2156905fa0842458d3711f96c057587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split dev to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb0a60f03414b2b9e11f06dbee298b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3469fb00862d4f989797fef056b6f54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87e9794d0db4381938481051d56e1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(\"pysentimiento/pt_sentiment\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration pysentimiento--pt_sentiment-76c273a313043bbf\n",
      "Found cached dataset parquet (/users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--pt_sentiment-76c273a313043bbf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370069686a1447ab02f1f9934eba6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "ds = load_dataset(\"pysentimiento/pt_sentiment\")\n",
    "\n",
    "\n",
    "ds = ds.map(\n",
    "    lambda x: {\"text\": preprocess_tweet(x[\"text\"], lang=\"pt\", preprocess_handles=False) }, \n",
    "    batched=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--pt_sentiment-76c273a313043bbf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-78fe03ea62b0119a.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7e6a9ab86c4c8e97d6e659128eda2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /users/jmperez/.cache/huggingface/datasets/pysentimiento___parquet/pysentimiento--pt_sentiment-76c273a313043bbf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-772a2effa661eee6.arrow\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, tweet_id. If text, tweet_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9600\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 900\n",
      "  Number of trainable parameters = 108927747\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/users/jmperez/.pyenv/versions/3.8.16/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/users/jmperez/.pyenv/versions/3.8.16/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/__main__.py\", line 3, in <module>\n",
      "    cli.cli(prog_name=\"python -m wandb\")\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/cli/cli.py\", line 102, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/cli/cli.py\", line 287, in service\n",
      "    server.serve()\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/server.py\", line 139, in serve\n",
      "    self._inform_used_ports(grpc_port=grpc_port, sock_port=sock_port)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/server.py\", line 67, in _inform_used_ports\n",
      "    pf.write(self._port_fname)\n",
      "  File \"/users/jmperez/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/port_file.py\", line 27, in write\n",
      "    f = tempfile.NamedTemporaryFile(prefix=bname, dir=dname, mode=\"w\", delete=False)\n",
      "  File \"/users/jmperez/.pyenv/versions/3.8.16/lib/python3.8/tempfile.py\", line 540, in NamedTemporaryFile\n",
      "    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n",
      "  File \"/users/jmperez/.pyenv/versions/3.8.16/lib/python3.8/tempfile.py\", line 250, in _mkstemp_inner\n",
      "    fd = _os.open(file, flags, 0o600)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpak0inlgd/port-2255664.txtb30u5is5'\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1105\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1104\u001b[0m wi \u001b[39m=\u001b[39m _WandbInit()\n\u001b[0;32m-> 1105\u001b[0m wi\u001b[39m.\u001b[39;49msetup(kwargs)\n\u001b[1;32m   1106\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:167\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprinter\u001b[39m.\u001b[39mdisplay(line, level\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl \u001b[39m=\u001b[39m wandb_setup\u001b[39m.\u001b[39;49msetup()\n\u001b[1;32m    168\u001b[0m \u001b[39m# Make sure we have a logger setup (might be an early logger)\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:307\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(settings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39m\"\u001b[39m\u001b[39m_WandbSetup\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 307\u001b[0m     ret \u001b[39m=\u001b[39m _setup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    308\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:302\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m wl \u001b[39m=\u001b[39m _WandbSetup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    303\u001b[0m \u001b[39mreturn\u001b[39;00m wl\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:288\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m _WandbSetup__WandbSetup(settings\u001b[39m=\u001b[39;49msettings, pid\u001b[39m=\u001b[39;49mpid)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:106\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check()\n\u001b[0;32m--> 106\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup()\n\u001b[1;32m    108\u001b[0m tracelog_mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_tracelog\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:234\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_manager()\n\u001b[1;32m    236\u001b[0m     sweep_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39msweep_param_path\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:262\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._setup_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager \u001b[39m=\u001b[39m wandb_manager\u001b[39m.\u001b[39;49m_Manager(settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py:112\u001b[0m, in \u001b[0;36m_Manager.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    113\u001b[0m     host \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/service.py:137\u001b[0m, in \u001b[0;36m_Service.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch_server()\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/service.py:130\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m ports_found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_ports(fname, proc\u001b[39m=\u001b[39;49minternal_proc)\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startup_debug_print(\u001b[39m\"\u001b[39m\u001b[39mwait_ports_done\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/service/service.py:69\u001b[0m, in \u001b[0;36m_Service._wait_for_ports\u001b[0;34m(self, fname, proc)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(fname):\n\u001b[0;32m---> 69\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args \u001b[39m=\u001b[39m get_training_arguments(model_name, task_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m\"\u001b[39m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, use_defaults_if_not_tuned\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, metric_for_best_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro_f1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m id2label \u001b[39m=\u001b[39m ds[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfeatures[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnames\n\u001b[0;32m---> 10\u001b[0m trainer, test_results \u001b[39m=\u001b[39m train_and_eval(\n\u001b[1;32m     11\u001b[0m     model_name, ds, id2label\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mneg\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mneu\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpos\u001b[39;49m\u001b[39m\"\u001b[39;49m], lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m, training_args\u001b[39m=\u001b[39;49mtraining_args, \n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/projects/pysentimiento/pysentimiento/training.py:192\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(base_model, dataset, id2label, lang, limit, metrics_fun, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m    Transformer classifier\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m train_huggingface(\n\u001b[1;32m    193\u001b[0m         base_model\u001b[39m=\u001b[39;49mbase_model, dataset\u001b[39m=\u001b[39;49mdataset, id2label\u001b[39m=\u001b[39;49mid2label,\n\u001b[1;32m    194\u001b[0m         lang\u001b[39m=\u001b[39;49mlang, metrics_fun\u001b[39m=\u001b[39;49mmetrics_fun, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    195\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/pysentimiento/pysentimiento/training.py:143\u001b[0m, in \u001b[0;36mtrain_huggingface\u001b[0;34m(base_model, dataset, id2label, metrics_fun, training_args, lang, max_length, auto_class, format_dataset, use_dynamic_padding, class_weight, trainer_class, data_collator_class, tokenize_fun, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     trainer_class\u001b[39m=\u001b[39mtrainer_class \u001b[39mor\u001b[39;00m Trainer\n\u001b[1;32m    141\u001b[0m trainer\u001b[39m=\u001b[39mtrainer_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_args)\n\u001b[0;32m--> 143\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    145\u001b[0m test_results\u001b[39m=\u001b[39mtrainer\u001b[39m.\u001b[39mpredict(dataset[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    146\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrm -Rf \u001b[39m\u001b[39m{\u001b[39;00moutput_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/trainer.py:1720\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step\n\u001b[1;32m   1718\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1720\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_handler\u001b[39m.\u001b[39;49mon_train_begin(args, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrol)\n\u001b[1;32m   1722\u001b[0m \u001b[39m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py:353\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    352\u001b[0m     control\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_train_begin\u001b[39;49m\u001b[39m\"\u001b[39;49m, args, state, control)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py:397\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    396\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 397\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(callback, event)(\n\u001b[1;32m    398\u001b[0m             args,\n\u001b[1;32m    399\u001b[0m             state,\n\u001b[1;32m    400\u001b[0m             control,\n\u001b[1;32m    401\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    402\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[1;32m    403\u001b[0m             optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[1;32m    404\u001b[0m             lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_scheduler,\n\u001b[1;32m    405\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    406\u001b[0m             eval_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader,\n\u001b[1;32m    407\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/integrations.py:747\u001b[0m, in \u001b[0;36mWandbCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     args\u001b[39m.\u001b[39mrun_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[0;32m--> 747\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(args, state, model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/transformers/integrations.py:721\u001b[0m, in \u001b[0;36mWandbCallback.setup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         init_args[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mrun_name\n\u001b[1;32m    719\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mrun \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wandb\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    722\u001b[0m         project\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mWANDB_PROJECT\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhuggingface\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    723\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_args,\n\u001b[1;32m    724\u001b[0m     )\n\u001b[1;32m    725\u001b[0m \u001b[39m# add config parameters (run may have been created manually)\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(combined_dict, allow_val_change\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/pysentimiento/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1128\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1128\u001b[0m     \u001b[39massert\u001b[39;00m logger\n\u001b[1;32m   1129\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39minterrupted\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n\u001b[1;32m   1130\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pysentimiento.training import train_and_eval\n",
    "from pysentimiento.tuning import get_training_arguments\n",
    "\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "\n",
    "training_args = get_training_arguments(model_name, task_name=\"sentiment\", lang=\"pt\", use_defaults_if_not_tuned=True, metric_for_best_model=\"macro_f1\")\n",
    "\n",
    "id2label = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "trainer, test_results = train_and_eval(\n",
    "    model_name, ds, id2label=id2label, lang=\"pt\", training_args=training_args, \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc79ed69e4c2b5a1db8fa17ebb1e82d66421519e5b018d314116a7b4cda9238"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
